{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79d0e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import numpy as np\n",
    "import sys, math, cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77310166",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) /Users/runner/work/opencv-python/opencv-python/opencv/modules/highgui/src/window.cpp:1006: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fdd11715fa2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"develop-012.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input Image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.4) /Users/runner/work/opencv-python/opencv-python/opencv/modules/highgui/src/window.cpp:1006: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "source": [
    "# Load the image\n",
    "img = cv2.imread(\"develop-012.jpg\")\n",
    "#cv2.imshow('Input Image', img)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c1d46",
   "metadata": {},
   "source": [
    "Convert the image to a different colorspace (HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7106cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to hsv space\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "#cv2.imshow('Input Image in HSV', hsv)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73308bb2",
   "metadata": {},
   "source": [
    "The next step is to remove the blue background from the image while in HSV colorspace by defining the upper and lower bounds of the color blue and using opencv inRange function to convert all the vlaues within that range to black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abe0482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove blue from the image\n",
    "upper_blue = np.array([135,255,255])  #-- upper range --\n",
    "lower_blue = np.array([85,50,0])  #-- lower range --\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "res = cv2.bitwise_not(hsv, hsv, mask= mask)  #-- Contains pixels having the gray color--\n",
    "\n",
    "img[mask!=0] =[0,0,0]\n",
    "cv2.imshow('Image without Blue',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca51487",
   "metadata": {},
   "source": [
    "This is a method to crop the black background by reading the image, converting it to grayscale by thresholding and finding the contours and cropping the image by using a bounding rectangle. It is not very effective, however, since the map isn't a 90 degree rectangle so there are black areas still within the bounding rectangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d42cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop the image\n",
    "#gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#_,thresh = cv2.threshold(gray,10,255,cv2.THRESH_BINARY)\n",
    "\n",
    "#contours,hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "#cnt = contours[0]\n",
    "#x,y,w,h = cv2.boundingRect(cnt)\n",
    "\n",
    "#crop = img[y:y+h,x:x+w]\n",
    "#cv2.imwrite(\"develop-001-cropped.jpg\", crop)\n",
    "\n",
    "#cv2.imshow('Result',crop)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c142f083",
   "metadata": {},
   "source": [
    "This next step find the contours of the dark part of the image to segment the map from the background.\n",
    "read image and convert to grayscale, then apply binary thresholding to get an idea of where the edges are located. Using a threshold value that makes most of the map white is ideal because the border will be detected easily.\n",
    "the next step is to find and draw the contours using the drawContours() method to overlay the contours on the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd77bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour and crop\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# apply binary thresholding\n",
    "# Any pixel with a value greater than 150 will be set \n",
    "# to a value of 255 (white)\n",
    "ret, img_thresh = cv2.threshold(img_gray, 10, 255, cv2.THRESH_BINARY)\n",
    "# visualize the binary image\n",
    "cv2.imshow('Binary image', img_thresh)\n",
    "cv2.waitKey(0)\n",
    "#cv2.imwrite('thresh1.jpg', img_thresh)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34affad",
   "metadata": {},
   "source": [
    "The CHAIN_APPROX_SIMPLE  algorithm compresses horizontal, vertical, and diagonal segments along the contour and leaves only their end points. This means that any of the points along the straight paths will be dismissed, and we will be left with only the end points. For example, consider a contour, along a rectangle. All the contour points, except the four corner points will be dismissed. This method is faster than the CHAIN_APPROX_NONE because the algorithm does not store all the points, uses less memory, and therefore, takes less time to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e1e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect the contours on the binary image using cv2.CHAIN_APPROX_NONE\n",
    "contours, hierarchy = cv2.findContours(image=img_thresh, \n",
    "                                       mode=cv2.RETR_TREE, \n",
    "                                       method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for c in contours:\n",
    "    epsilon = 0.1 * cv2.arcLength(c, True)\n",
    "    approx_rectangle = cv2.approxPolyDP(c, epsilon, True)\n",
    "    if len(approx_rectangle) == 4:\n",
    "        break\n",
    "        \n",
    "# draw contours on the original image\n",
    "image_copy = img.copy()\n",
    "cv2.drawContours(image=image_copy, contours=c, \n",
    "                 contourIdx=0, color=(0, 255, 0), \n",
    "                 thickness=2, lineType=cv2.LINE_AA)\n",
    "               \n",
    "# see the results\n",
    "cv2.imshow('Image with Contours', image_copy)\n",
    "cv2.waitKey(0)\n",
    "#cv2.imwrite('contours_none_image1.jpg', image_copy)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d9e2b6",
   "metadata": {},
   "source": [
    "Use perspective transform to reshape the map by providing the points on the image from which to gather information and wrap the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eafd3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epsilon = 0.1 * cv2.arcLength(contours[0], True)\n",
    "#approx_rectangle = cv2.approxPolyDP(contours[0], epsilon, True)\n",
    "#print(approx_rectangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8ef1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = approx_rectangle[0][0]\n",
    "b = approx_rectangle[1][0]\n",
    "c = approx_rectangle[2][0]\n",
    "d = approx_rectangle[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f10018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pts = cv2.drawContours(img, approx_rectangle, -1, (0, 255, 0), 3)\n",
    "cv2.imshow(\"Image with Edge Points\", img_pts)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e0396a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wid_ad = np.sqrt(((a[1] - d[1])**2) + ((a[0] - d[0])**2))\n",
    "wid_cb = np.sqrt(((c[1] - b[1])**2) + ((c[0] - b[0])**2))\n",
    "len_dc = np.sqrt(((d[1] - c[1])**2) + ((d[0] - c[0])**2))\n",
    "len_ab = np.sqrt(((a[1] - b[1])**2) + ((a[0] - b[0])**2))\n",
    "print(wid_ad)\n",
    "print(wid_cb)\n",
    "print(len_dc)\n",
    "print(len_ab)\n",
    "\n",
    "max_width = max(int(wid_ad), int(wid_cb))\n",
    "max_length = max(int(len_dc), int(len_ab))\n",
    "print(max_width, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06c4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "wid_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2dc246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate points of the documents\n",
    "# or object which you want to transform\n",
    "# pts1 is the original coordinates of the image\n",
    "# pts2 is the coordinates used to transform the image\n",
    "pts1 = np.float32([b, c, d, a])\n",
    "\n",
    "pts2 = np.float32([[0,0],\n",
    "                   [0, max_width],\n",
    "                   [max_length, max_width],\n",
    "                   [max_length, 0]])\n",
    "\n",
    "# Apply Perspective Transform Algorithm\n",
    "matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "img_cropped = cv2.warpPerspective(img_pts, matrix, ( max_length,max_width))\n",
    "cv2.imshow(\"Image Cropped & Transformed\", img_cropped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb7c6a7",
   "metadata": {},
   "source": [
    "Next step is to find the contour of the green arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f308486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the green contour runs inside this loop\n",
    "run = 1\n",
    "i = 0\n",
    "while run:\n",
    "    # convert again to hsv space\n",
    "    hsv = cv2.cvtColor(img_cropped, cv2.COLOR_BGR2HSV)\n",
    "    img_pts = 0\n",
    "    # remove green from the image\n",
    "    upper_green = np.array([75, 255, 255]) #-- upper range --\n",
    "    lower_green = np.array([45, 100, 100])  #-- lower range --\n",
    "    mask_green = cv2.inRange(hsv, lower_green, upper_green)\n",
    "\n",
    "    # detect the contours on the binary image using cv2.CHAIN_APPROX_NONE\n",
    "    contours, hierarchy = cv2.findContours(image=mask_green, \n",
    "                                           mode=cv2.RETR_TREE, \n",
    "                                           method=cv2.CHAIN_APPROX_NONE)\n",
    "    #################\n",
    "    # draw the contours around the arrow to see the points \n",
    "    img_pts = cv2.drawContours(img_cropped, contours, -1, (255, 0, 0), 3)\n",
    "    cv2.imshow('Image Rotated Upright', img_pts)\n",
    "    cv2.waitKey(0)\n",
    "    # write a for loop to find the biggest contour\n",
    "    for c in contours:\n",
    "        epsilon = 0.1 * cv2.arcLength(c, True)\n",
    "        approx_polygon = cv2.approxPolyDP(c, epsilon, True)\n",
    "        if len(approx_polygon) > 3 and cv2.contourArea(c) < 1000:\n",
    "            break\n",
    "    arrow_region = approx_polygon[0][0]   \n",
    "    print(arrow_region)\n",
    "    if arrow_region[0] > 700 and arrow_region[1] < 500:\n",
    "        run = 0   \n",
    "    else:\n",
    "        img_cropped = cv2.rotate(img_cropped, cv2.ROTATE_180)\n",
    "        #i = i + 1\n",
    "        #if i == 2:\n",
    "        #run = 0\n",
    "    print(cv2.contourArea(c))   \n",
    "        # add an exception handler that stops the code \n",
    "        # after rotating 3 times other wise it might rotate \n",
    "        # infinitely with some images\n",
    "# see the results\n",
    "cv2.imshow('Image Rotated Upright', img_cropped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fe10c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Lower_Red_1 = np.array([0,100,30]    ,dtype= \"uint8\") \n",
    "Upper_Red_1 = np.array([30,255,255], dtype=\"uint8\")\n",
    "\n",
    "Lower_Red_2 = np.array([145,100,30]    ,dtype= \"uint8\") \n",
    "Upper_Red_2 = np.array([225,255,255], dtype=\"uint8\")\n",
    "\n",
    "\n",
    "hsv = cv2.cvtColor(img_cropped, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "mask = cv2.inRange(hsv ,  Lower_Red_1, Upper_Red_1) + cv2.inRange(hsv,  Lower_Red_2, Upper_Red_2)\n",
    "\n",
    "cv2.imshow('Map+Contour',mask)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "print(contours)\n",
    "\n",
    "\n",
    "for i,c in  enumerate(contours):    \n",
    "    peri   = cv2.arcLength(c, True)\n",
    "    approx_triangle = cv2.approxPolyDP(c, 0.04 * peri, True)\n",
    "    \n",
    "    if len(approx_triangle)== 3:\n",
    "        break\n",
    "     \n",
    "    \n",
    "#print(approx)\n",
    "\n",
    "\n",
    "Contour_Map = cv2.drawContours(img_cropped, c, 1,(0,255,0), 1)\n",
    "\n",
    "cv2.imshow('Map+Contour',Contour_Map)\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a2393",
   "metadata": {},
   "source": [
    "To remove red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0e4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to hsv space\n",
    "hsv = cv2.cvtColor(img_cropped, cv2.COLOR_BGR2HSV)\n",
    "# remove red from the image\n",
    "# red has two regions on the color spectrum\n",
    "lower_red1 =np.array([0,100,30]    ,dtype= \"uint8\") \n",
    "upper_red1 = np.array([30,255,255], dtype=\"uint8\")\n",
    "lower_red2 = np.array([145,100,30]    ,dtype= \"uint8\") \n",
    "upper_red2 = np.array([225,255,255], dtype=\"uint8\")\n",
    "# generate the lower and upper mask of red\n",
    "mask_red1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "mask_red2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "# merge the masks\n",
    "#mask_red = cv2.bitwise_or(mask_red1, mask_red2)\n",
    "mask_red = mask_red1+mask_red2\n",
    "    \n",
    "# detect the contours on the binary image using cv2.CHAIN_APPROX_NONE\n",
    "contours, hierarchy = cv2.findContours(image=mask_red, \n",
    "                                       mode=cv2.RETR_TREE, \n",
    "                                       method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.imshow('Image with Red Mask', mask_red)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278efb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask_red1+mask_red2\n",
    "#cv2.imshow('Image with Red Mask', mask_red)\n",
    "#cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14688124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a for loop to find the contour\n",
    "#for i, c in enumerate(contours):\n",
    "    #epsilon = cv2.arcLength(c, True)\n",
    "   # approx_triangle = cv2.approxPolyDP(c, 0.4*epsilon, True)\n",
    "    #if len(approx_triangle) == 3:\n",
    "        #break\n",
    "\n",
    "# draw contours on the original image\n",
    "#image_copy = img_cropped.copy()\n",
    "#cv2.drawContours(image=image_copy, contours=c, \n",
    "                 #contourIdx=c, color=(0, 255, 0), \n",
    "                 #thickness=2, lineType=cv2.LINE_AA)\n",
    "#gh =cv2.drawContours(img_cropped, c, 1,(0,255,0), 5)              \n",
    "# see the results\n",
    "#cv2.imshow('Image with Contours', gh)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d20474",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2656660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The red pointer is an isosceles triangle, by finding the length\n",
    "# of the sides, we can determine from the lengths with roughly equal \n",
    "# sides which one is the pointer and use that to find the position\n",
    "a = approx_triangle[0][0]\n",
    "b = approx_triangle[1][0]\n",
    "c = approx_triangle[2][0]\n",
    "\n",
    "ab = np.sqrt(((a[1] - b[1])**2) + ((a[0] - b[0])**2))\n",
    "bc = np.sqrt(((c[1] - b[1])**2) + ((c[0] - b[0])**2))\n",
    "ca = np.sqrt(((c[1] - a[1])**2) + ((c[0] - a[0])**2))\n",
    "\n",
    "print(ab)\n",
    "print(bc)\n",
    "print(ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5a6b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the two sides of the triangle are roughly the same size and both geeater than 130,\n",
    "# the smallest side is the opposite of the pointer\n",
    "if ab > 100 and bc > 100:\n",
    "    point = b\n",
    "elif bc > 100 and ca > 100:\n",
    "    point = c\n",
    "elif ca > 100 and ab > 100:\n",
    "    point = a\n",
    "print(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ee66a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ab < 130:\n",
    "    midpoint = (a+b)/2\n",
    "elif bc < 130:\n",
    "    midpoint = (b+c)/2\n",
    "elif ca < 130:\n",
    "    midpoint = (a+c)/2 \n",
    "print(midpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65809cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find the position of the pointer:\n",
    "xposs = point[0]\n",
    "yposs = point[1]\n",
    "\n",
    "xpos = xposs/max_length\n",
    "ypos = 1 - (yposs/max_width)\n",
    "print(f\"POSITION {xpos:.3f} {ypos:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb474b0c",
   "metadata": {},
   "source": [
    "To calculate bearing, we will use trigonometric functions and the coordinates from the red pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = midpoint\n",
    "y = point\n",
    "hdg = ((np.arctan2((y[1]-x[1]), (y[0]-x[0]))*180/np.pi))+90\n",
    "print(f\"POSITION {xpos:.3f} {ypos:.3f}\")\n",
    "print(f\"BEARING {hdg:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#math.atan2((y[1]-x[1]), (y[0]-x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12be003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#math.degrees(math.atan2((y[1]-x[1]), (y[0]-x[0])))+90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2b30fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/67962200/python-opencv-perspective-transformation-problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/perspective-transformation-python-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece76fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/python-opencv-cv2-rotate-method/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f3f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.thoughtco.com/understanding-the-distance-formula-2312242"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
